{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 12:21:54.971261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-27 12:21:55.070919: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-27 12:21:55.534008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/theshadow/miniconda3/lib/:/home/theshadow/miniconda3/envs/si-cctv/lib/:/home/theshadow/miniconda3/envs/si-cctv/lib/:/home/theshadow/miniconda3/envs/si-cctv/lib/\n",
      "2023-01-27 12:21:55.534068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/theshadow/miniconda3/lib/:/home/theshadow/miniconda3/envs/si-cctv/lib/:/home/theshadow/miniconda3/envs/si-cctv/lib/:/home/theshadow/miniconda3/envs/si-cctv/lib/\n",
      "2023-01-27 12:21:55.534072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 12:21:56.016223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-27 12:21:56.024667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-27 12:21:56.024788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "import cv2\n",
    "\n",
    "#print the number of GPUs available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people:  5749\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pathLFW = './LFW/lfw_funneled/'\n",
    "\n",
    "#take the first 100 folders\n",
    "folders = os.listdir(pathLFW)[:]\n",
    "\n",
    "#the idea is to create a dataset for a siamese network. We have to create a list of tuples (image1, image2, label) where label is 1 if the two images are of the same person and 0 otherwise\n",
    "#if there is a person with only one image, we discard use it for the training in the false case\n",
    "\n",
    "#create a dictionary with the name of the person as key and the list of images as value\n",
    "diz = {}\n",
    "for folder in folders:\n",
    "    #check if its actually a folder\n",
    "    if not os.path.isdir(pathLFW + folder):\n",
    "        continue\n",
    "    #read the RGB images\n",
    "    images = [cv2.imread(pathLFW + folder + '/' + img) for img in os.listdir(pathLFW + folder) if img.endswith('.jpg')]\n",
    "    diz[folder] = images\n",
    "\n",
    "\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "\n",
    "print('Number of people: ', len(diz))\n",
    "\n",
    "firstPair = False\n",
    "\n",
    "\n",
    "for nome in diz.keys():\n",
    "    if len(diz[nome]) == 1:\n",
    "        #print(\"ciao\")\n",
    "        if not firstPair:   #if it was already been found a person with only one image then we have created a tuple\n",
    "            img1 = diz[nome][0]\n",
    "            #resize the image into a 160x160 image\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            firstPair = True\n",
    "            \n",
    "        else:\n",
    "            img2 = diz[nome][0]\n",
    "            #resize the image into a 160x160 image\n",
    "            \n",
    "            tupla = (img1, img2)\n",
    "            train_x.append(tupla)\n",
    "            train_y.append(0)\n",
    "            firstPair = False\n",
    "    else:\n",
    "        #print(\"ciao2\")\n",
    "        #create a for with step 2\n",
    "        for i in range(0, len(diz[nome]), 2):\n",
    "            #check if i + 1 is out of range\n",
    "            if i + 1 >= len(diz[nome]):\n",
    "                if not firstPair:   #if it was already been found a person with only one image then we have created a tuple\n",
    "                    img1 = diz[nome][i]\n",
    "                    \n",
    "                    firstPair = True\n",
    "                    \n",
    "                else:\n",
    "                    img2 = diz[nome][i]\n",
    "                    \n",
    "                    tupla = (img1, img2)\n",
    "                    train_x.append(tupla)\n",
    "                    train_y.append(0)\n",
    "                    firstPair = False\n",
    "                continue\n",
    "            img1 = diz[nome][i]\n",
    "           \n",
    "\n",
    "            img2 = diz[nome][i+1]\n",
    "        \n",
    "            tupla = (img1, img2)\n",
    "            train_x.append(tupla)\n",
    "            train_y.append(1)\n",
    "\n",
    "\n",
    "#train x in a numpy array\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 12:22:04.492241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-27 12:22:04.492968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-27 12:22:04.493139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-27 12:22:04.493238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-27 12:22:04.877420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-27 12:22:04.877591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-27 12:22:04.877692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-27 12:22:04.877797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3675 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-01-27 12:22:07.803170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-01-27 12:22:08.377909: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-01-27 12:22:08.379066: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2023-01-27 12:22:08.379076: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n",
      "2023-01-27 12:22:08.379115: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-01-27 12:22:09.706972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "embedder = FaceNet()\n",
    "\n",
    "#set verbose to 0 to avoid printing the progress bar in tensorflow\n",
    "\n",
    "\n",
    "from IPython.utils import io\n",
    "with io.capture_output() as captured:\n",
    "    train_embeddings_x = []\n",
    "    for i in range(train_x.shape[0]):\n",
    "        print(i)\n",
    "        print(train_x[i][0].shape)\n",
    "        print(train_x[i][1].shape)\n",
    "        emb1 = embedder.extract(train_x[i][0], threshold=0.95)\n",
    "        emb2 = embedder.extract(train_x[i][1], threshold=0.95)\n",
    "        train_embeddings_x.append((emb1, emb2))\n",
    "\n",
    "    train_embeddings_x = np.array(train_embeddings_x)\n",
    "\n",
    "print(train_embeddings_x.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save train embeddings and train y\n",
    "np.save('train_embeddings_x.npy', train_embeddings_x)\n",
    "np.save('train_y.npy', train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('si-cctv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c73208cc7c35a2399647dfd68c969190c7caf105886c1e4d458f6f5ad06c724e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
